#!/usr/bin/env python3 

import datetime, time
import sys,os,json,ast,requests,wget,io
from vecml import vecml
import numpy as np
from contextlib import redirect_stdout
import cgi, cgitb

# secrets that we do not want to share
fn = os.environ["HOME"] + '/.secrets.json'
assert 'VECML_API_KEY' in os.environ or os.path.exists(fn), 'VECML_API_KEY is required; see README for https://github.com/kwchurch/RAG'

secrets = {}
if os.path.exists(fn):
    with open(fn, 'r') as fd:
        secrets = ast.literal_eval(fd.read().rstrip())

def s2_apikey():
    if 'S2_API_KEYS' in secrets: 
        return secrets['S2_API_KEYS'][0]
    return os.environ['S2_API_KEY']

def vecml_apikey():
    if 'VECML_API_KEYS' in secrets:
        return secrets['VECML_API_KEYS'][0]
    return os.environ['VECML_API_KEY']

def my_get(rec, keys):
    if rec is None: return None
    if len(keys) == 0: return None
    if keys[0] in rec:
        if not keys[0] in rec: return None
        v = rec[keys[0]]
        if len(keys) == 1: return v
        else: return my_get(v, keys[1:])
    return None

RAG_filenames = 0
def get_RAG_filename(suffix='html'):
    global RAG_filenames
    RAG_filenames += 1
    fn = 'tmp/compare_and_contrast.%d.%05d.%s' % (os.getpid(), RAG_filenames, suffix)
    return fn

def download_pdfs(pdfs):
    successes = []
    failures = []
    for pdf in pdfs:
        fn = get_RAG_filename('pdf')
        try:
            success = wget.download(pdf, out=fn)
            successes.append(fn)
        except Exception as e:
            # print('exception in download_pdfs: ' + str(pdf) + ' exception: ' + str(e), file=sys.stderr)
            failures.append(pdf)
    return successes,failures

def id_ify(s):
    if s is None: return s
    if len(s) == 40: return s
    # s = s.replace('%3A', ':')
    for prefix in ['CorpusId:', 'PMID:', 'ACL:', 'arXiv:', 'DBLP:', 'MAG:']:
        if s.startswith(prefix):
            return s
    if '/' in s: return s
    return 'CorpusId:' + s

def convert_id(id, new_type):
    if id.startswith(new_type):
        return id[len(new_type)+1:]
    else:
        my_api = 'https://api.semanticscholar.org/graph/v1/paper/'
        cmd = my_api + str(id) + '/?fields=externalIds'
        k = s2_apikey()
        if k is None:
            j = requests.get(cmd).json()
        else:
            j = requests.get(cmd, headers={"x-api-key": k}).json()
        if 'externalIds' in j:
            return j['externalIds'][new_type]

def convert_ids(ids, new_type):
    return [convert_id(i, new_type) for i in ids ]

print('Access-Control-Allow-Origin: *\r\nContent-type: application/json\r\n\r\n')

res = []
scores = []

form = cgi.FieldStorage() 
# form = Form()


required_arguments = ['ids']
optional_arguments = ['help']

def unsupported_arguments():
    res = []
    for k in form.keys():
        if k in required_arguments: continue
        if k in optional_arguments: continue
        res.append(k)
    return res

def documentation():
    inputs = {}
    j = {'required_arguments': required_arguments,
         'optional_arguments': optional_arguments,
         'inputs': inputs}
    for k in form.keys():
        inputs[k] = form.getvalue(k)

    err = {'missing_required_arguments' : [k for k in required_arguments if form.getvalue(k) is None],
         'unsupported_arguments' : unsupported_arguments()}
    if len(err['missing_required_arguments']) > 0 or len(err['unsupported_arguments']) > 0:
        j['errors'] = err
        print(json.dumps(j))
        sys.exit()

    inputs['normalized_ids'] = [ id_ify(id) for id in inputs['ids'].split(',') ]

    return j

def usage():
    j = documentation()
    print(json.dumps(j))
    sys.exit()

if not form.getvalue('help') is None:
    usage()

def pdfs_for_paper(paper):
    res = []
    pubmedcentral = my_get(paper, ['externalIds', 'PubMedCentral'])
    if not pubmedcentral is None:
        res.append('https://www.ncbi.nlm.nih.gov/pmc/articles/PMC' + str(pubmedcentral) + '/')
    arxiv = my_get(paper, ['externalIds', 'arXiv'])
    if not arxiv is None:
        res.append('https://arxiv.org/pdf/' + str(arxiv))
    acl = my_get(paper, ['externalIds', 'ACL'])
    if not acl is None:
        res.append('https://aclanthology.org/' + str(acl) + '.pdf')
    oa = my_get(paper, ['openAccessPdf', 'url'])
    if not oa is None:
        res.append(oa)
    return res
    
def lookup_papers(ids, fields, limit=None):
    p = {'fields': fields}
    if not limit is None: p['limit']=limit
    k = s2_apikey()
    if k is None:
        return requests.post(
            'https://api.semanticscholar.org/graph/v1/paper/batch',
            params=p,
            json={"ids": ids}).json()
    else:
        return requests.post(
            'https://api.semanticscholar.org/graph/v1/paper/batch',
            params=p,
            json={"ids": ids},
            headers={"x-api-key": s2_apikey()}).json()

def create_multiple_paper_details_files(j, ids):
    j['papers'] = papers = lookup_papers(ids, 'externalIds,abstract,title,openAccessPdf,tldr,url')
    files = []
    j['failed_in_wget'] = failures = []
    for i,paper in zip(ids,papers):
        fn = get_RAG_filename('html')
        files.append(fn)
        with open(fn, 'w') as fd:
            # print("Content-type:text/html\r\n\r\n", file=fd)
            print('<html>', file=fd)
            print("<head>", file=fd)
            print("</head>", file=fd)
            print("<body>", file=fd)

            cid = my_get(paper, ['externalIds', 'CorpusId'])
            if cid is None:
                j['error'] = 'cannot find corpusid for: ' + str(i)
                print(json.dumps(j))
                sys.exit()

            if 'title' in paper and 'url' in paper:
                print('<h2>Title: <a href="%s">%s</a></h2>' %(paper['url'], paper['title']), file=fd)
            else:
                print('<h2>CorpusId: ' + str(cid) + '</h2>', file=fd)                

            pdfs = pdfs_for_paper(paper)

            # print('paper: ' + str(paper), file=sys.stderr)
            # print('pdfs: ' + str(pdfs), file=sys.stderr)

            if not pdfs is None:
                downloaded_pdfs,not_downloaded_pdfs = download_pdfs(pdfs)
                for p in downloaded_pdfs: files.append(p)
                for p in not_downloaded_pdfs: failures.append(p)

            tldr = my_get(paper, ['tldr', 'text'])
            if not tldr is None:
                print('<p><b>tl;dr:</b> ' + str(tldr), file=fd)

            abstract = my_get(paper, ['abstract'])
            if not abstract is None:
                print('<p><b>Abstract:</b> ' + str(abstract), file=fd)

            bibtex = my_get(paper, ['citationStyles', 'bibtex'])
            if not bibtex is None:
                print('<p><b>Citation:</b> <pre>', file=fd)
                print(bibtex, file=fd)
                print('</pre>', file=fd)

            print('</body></html>', file=fd)
    return files

def chat_about_paper(name, prompt):
    try:
        return vecml.chat(name, prompt)
    except Exception as e:
        return 'VecML error: ' + str(e)

def RAG_feature(j, ids):

    times = [time.time()]
    times_descriptions = []

    if ids is None or len(ids) != 2:
        return

    files = create_multiple_paper_details_files(j, ids)

    times_descriptions.append('create_tmp_files')
    times.append(time.time())

    paper0 = j['papers'][0]
    title0 = paper0['title']
    paper0['files_uploaded_to_VecML'] = files

    f = io.StringIO()
    with redirect_stdout(f):
        vecml.init(vecml_apikey() ,"us-west")

    times_descriptions.append('VecML init')
    times.append(time.time())

    vecml.create_chat(files[0], files)

    times_descriptions.append('VecML create chat')
    times.append(time.time())

    paper0['summary'] = chat_about_paper(files[0], 'Imagine I am a reviewer of this paper.  Please summarize "%s"' % (title0))

    times_descriptions.append('Summarize paper 0')
    times.append(time.time())

    for i,paper in enumerate(j['papers'][1:]):
        title = paper['title']

        prompt = 'Imagine I am a reviewer of this paper.  Please summarize "%s"' % (title)
        paper['summary'] = chat_about_paper(files[0], prompt)

        times_descriptions.append('Summarize paper ' + str(i+1))
        times.append(time.time())

        prompt = 'Imagine I am a reviewer of this paper.  What does "%s" have in common with "%s"?' % (title, title0)
        paper['similarities'] = chat_about_paper(files[0], prompt)

        times_descriptions.append('Similarities for paper ' + str(i+1))
        times.append(time.time())

        prompt = 'Imagine I am a reviewer of this paper.  What distinguishes "%s" from "%s"?' % (title, title0)
        paper['differences'] = chat_about_paper(files[0], prompt)

        times_descriptions.append('Differences for paper ' + str(i+1))
        times.append(time.time())

    paper0['times'] = { 'desc' : times_descriptions, 'times' : np.diff(np.array(times)).tolist()}
    vecml.delete_data(files[0])

j = documentation()
RAG_feature(j, my_get(j, ['inputs', 'normalized_ids']))
print(json.dumps(j))

